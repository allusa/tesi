\chapter{Implementació amb para\l.lelisme}

En el capítol \todo{ref al capítol} hem definit la funció de
multiresolució com una funció sobre una sèrie temporal. Aquesta funció
té bàsicament dues parts: un plec sobre un esquema de multiresolució i
mapes sobre la sèrie temporal. Ara implementem
aquesta funció mitjançant computació para\l.lela.


Una tècnica de computació para\l.lela és
MapReduce \parencite{deanghemawat04:mapreduce}, la qual s'adequa bé al
problema ja que es basa en aplicar operacions de mapa (\emph{map}) i
posteriorment plegar-les (\emph{reduce}). Un sistema que es basa
exclusivament en aquesta tècnica és
Hadoop \parencite{hadoop}.

A continuació, en primer lloc, estudiem Hadoop i la tècnica MapReduce.
En segon lloc, implementem usant Hadoop un \gls{SGSTM} anomenat
\emph{RoundRobindoop}. Aquest és un \gls{SGSTM} específic amb
l'objectiu de mostrar una implementació que resolgui la multiresolució
d'una sèrie temporal en temps diferit (\emph{offline}) i computant
para\l.lelament.




\section{Hadoop i MapReduce}


Apache Hadoop, o simplement Hadoop, \parencite{hadoop} és un sistema
de computació distribuïda que permet processar grans volums de dades
amb diferents computadors en para\l.lel. El sistema inclou la gestió
de l'emmagatzematge per a distribuir les dades als diferents
computadors, la qual cosa s'anomena \gls{HDFS}; la gestió dels
diferents processos en els diversos computadors; i el model de
programació para\l.lela, el qual és MapReduce.


MapReduce \parencite{deanghemawat04:mapreduce,lammel08:mapreduce} és
un model de programació per processar algoritmes en para\l.lel. Es
basa en resoldre els algoritmes en dues etapes: primer en una etapa de
\emph{maps} i segon en una etapa de \emph{reduces}.  Aquestes dues
etapes són l'algoritme bàsic i per això s'anomena MapReduce, tot i que
hi ha variacions que afegeixen més etapes.  Els noms de \emph{map} i
\emph{reduce} també s'usen per a les operacions d'alt ordre, com les
mapa (\emph{map}) i plec (\emph{fold} o també \emph{reduce}), que hem
definit en el model dels \gls{SGST}, però
\textcite{lammel08:mapreduce} compara les de MapReduce amb les d'alt
ordre i conclou que no són exactament el mateix; aquí distingirem els
conceptes usant els noms en anglès map i reduce per a MapReduce.


A la~\autoref{fig:mapreduce:esquema}
es mostra l'esquema de funcionament de MapReduce, que és el següent:


\begin{figure}[tp]
  \centering
  \input{imatges/implementacio/mapreduce.tex}
  \caption{Esquema de funcionament de MapReduce}
  \label{fig:mapreduce:esquema}
\end{figure}



\begin{enumerate}

\item Hi ha unes dades originals que es poden partir en
  trossos. Hadoop està orientat a fitxers, mitjançant \gls{HDFS}, i
  per tant cada tros de dades és cadascun dels fitxers que es volen
  processar o bé conjunts de línies d'un fitxer.

\item Cada tros de les dades es processa mitjançant una operació
  map. Cada map es pot computar en para\l.lel i distribuït.

\item Cada operació map ha de retornar un nou conjunt de dades
  formats per parelles d'identificador i valor. Aquests conjunts de
  dades s'ordenen per identificador. 

\item Cada conjunt de dades amb el mateix identificador es processa
  mitjançant una operació reduce. Cada reduce es pot computar en
  para\l.lel i distribuït.

\item Cada reduce ha de retornar un tros del resultat final. És a dir,
  que unint les dades que retornen els reduce s'obtenen les dades
  finals. En l'orientació a fitxers de Hadoop, el resultat final és un
  fitxer, o bé un tros d'un fitxer, per a cada reduce.

\end{enumerate}



Per a resoldre un algoritme amb MapReduce, cal definir l'operació de
map i l'operació de reduce. El map ha de calcular un filtre sobre les
dades, sobretot establir grups de dades, i el reduce ha de calcular
agregacions o resums per a cada grup. MapReduce té una gran similitud
amb l'operació \emph{summarize} dels
\gls{SGBDR} \parencite[cap.~7]{date04:introduction8}, però separada
convenientment en les dues etapes.  A més, MapReduce imposa les
següents restriccions: les dades s'han de poder partir i l'algoritme
s'ha de poder expressar separat en les dues operacions de map i de
reduce.  \textcite{deanghemawat04:mapreduce} mostren exemples
d'algoritmes que es poden expressar amb MapReduce.



Un cop s'ha modelat un algoritme amb MapReduce, aleshores Hadoop ja és
capaç d'executar els maps i els reduces en para\l.lel i distribuïts. A
més, Hadoop també gestiona el compromís dels recursos entre el temps
de distribuir les dades, la quantitat de processos en para\l.lel que
s'han de crear i el temps afegit que suposa cada procés nou.








\section{RoundRobindoop}


\todo{}

RoundRobindoop implementa un \gls{SGSTM} específic que resol la funció
de multiresolució amb el model de programació MapReduce. 
\todo{atenció només resol l'operació de Dmap!}

Primer, dissenyem les operacions de MapReduce per a la multiresolució. Segon, 



\subsection{Multiresolució amb MapReduce}

L'algoritme que implementem amb MapReduce és el de la funció de
multiresolució definida a la secció \todo{ref secció
  sec:multiresolucio:funcio}. Aquesta funció principalment té dues
parts, una de mapa i una de plec, que com ja s'ha dit no es poden
correspondre exactament amb les operacions de map i de reduce. 
 Així
doncs, dissenyem les operacions de map i de reduce que tenen el mateix
efecte que calcular la funció de multiresolució, en què el resultat
final no és la sèrie temporal total sinó el resultat de totes les
funcions $\glssymbol{not:sgstm:dmap}$, és a dir el resultat final són
les sèries temporals dels discs del model de \gls{SGSTM} la
concatenació dels quals resulta en la sèrie temporal total.



Sigui $S=\{m_0,m_1,\dotsc,m_k\}$ una sèrie temporal, i $e = \{
(\delta_0,f_0,\tau_0,k_0),\ldots, (\delta_d,f_d,\tau_d,k_d)\}$ els
paràmetres d'un esquema de multiresolució, definim l'algoritme
MapReduce que calcula $\operatorname{mapreduce}(S,e) = \{
(\delta_0,f_0,
\glssymbol{not:sgstm:dmap}(S,\delta_0,f_0,\tau_0,k_0)),\dotsc,
(\delta_c,f_c,\glssymbol{not:sgstm:dmap}(S,\delta_c,f_c,\tau_c,k_c))
\}$. És a dir, calcula tots els $\glssymbol{not:sgstm:dmap}$ possibles
i els identifica amb el pas de consolidació $\delta$ i la funció
d'agregació d'atributs $f$, els quals identifiquen les subsèries
resolució assumint que no n'hi ha de repetits.
%i que per tant tenenassociats el cardinal màxim $k$ i un instant de consolidació $\tau$.





L'esquema de funcionament de RoundRobindoop és el de
la~\autoref{fig:roundrobindoop:esquema}, el qual és la implementació
particular de l'esquema de la~\autoref{fig:mapreduce:esquema} per a la
multiresolució. A continuació expliquem com són les dades originals,
les d'entremig i les finals, i per tant quina operació realitzen els
map i els reduce.





\begin{figure}[tp]
  \centering

  \begin{tikzpicture}

      \tikzset{
        mynode/.style={rectangle,rounded corners,draw=black, 
          very thick, inner sep=1em, minimum size=3em, text centered,
          groc},
        myarrow/.style={->, shorten >=1pt, thick},
        mylabel/.style={text width=7em, text centered},
        groc/.style={top color=white, bottom color=yellow!50},
        verd/.style={top color=white, bottom color=green!50},
        roig/.style={top color=white, bottom color=red!50},
      }  




 \node[mynode,verd] (m1) {map 1};
 \node (ml1) [below=of m1] {};
 \node[mynode,verd] (m2) [below=of ml1] {map 2};
 \node (ml2) [below=of m2] {};
 \node[mynode,verd,dotted] (mn) [below=of ml2] {map M};


 \node[mynode] (d1) [right=0.5cm of m1] {
   \begin{tabular}{|c|cc|}\hline
     \multirow{2}{*}{$B$} & \multicolumn{2}{|c|}{valor} \\\cline{2-3}
       & \multicolumn{1}{|c|}{t} & v \\\hline
      & & \\
      & &\\\hdashline
      & &\\
      & &\\\hline
   \end{tabular}
 };

 \node[mynode] (d2) [right=0.5cm of m2] {
   \begin{tabular}{|c|cc|}\hline
     \multirow{2}{*}{$B$} & \multicolumn{2}{|c|}{valor} \\\cline{2-3}
       & \multicolumn{1}{|c|}{t} & v \\\hline
      & &\\\hdashline
      & &\\\hline
   \end{tabular}
 };

 \node[mynode,dotted] (dn) [right=1.5cm of mn] {};



 \node[mynode,verd] (r1) [right=0.5cm of d1] {\parbox{1cm}{reduce $\delta_0,f_0$}};
 \node[mynode,verd] (r2) [below=2cm of r1] {\parbox{1cm}{reduce $\delta_1,f_1$}};
 \node[mynode,verd,dotted] (rn) [right=1cm of dn] {\parbox{1cm}{reduce $\delta_d,f_d$}};




 \node[mynode] (o) [above left=of m1, anchor=north east] {
   \begin{tabular}{|c|}\hline
     t v \\\hline
       \\
       \\
     \parbox[c][7cm][s]{0cm}{\vfill} \\
       \\
       \\\hline
   \end{tabular}
 };
 \node [above=0cm of o] {$S$ original};
 \node[mynode,minimum height=10cm] (f) [above right=of r1, anchor=north west] {
   \begin{tabular}{|c|}\hline
    $\delta\, f$ t v \\\hline
       \\
        \\
     \parbox[c][7cm][s]{0cm}{\vfill}  \\
        \\
        \\\hline
   \end{tabular}
};
 \node [above=0cm of f] {final};




 \draw[dashed] (ml1) -- (ml1-|o.west);
 \draw[dashed] (ml2) -- (ml2-|o.west);

 \draw[myarrow] (o.center|-m1) -- (m1)  node[sloped,above,near end] {$S'_1$};
 \draw[myarrow] (o.center|-m2) -- (m2) node[sloped,above,near end] {$S'_2$};
 \draw[myarrow,dotted] (o.center|-mn) -- (mn) node[sloped,above,near end] {$S'_M$};


 \draw[myarrow] (m1) -- (d1);
 \draw[myarrow] (m2) -- (d2);
 \draw[myarrow,dotted] (mn) -- (dn);

 \draw[myarrow] (d1.center) -- (r1);
 \node (d1b) [above=3ex of d1.280] {}; 
 \draw[myarrow] (d1b.center) -- (r2);

 \draw[myarrow] (d2.center) -- (r1);
 \node (d2b) [above=3ex of d2.280] {}; 
 \draw[myarrow] (d2b.center) -- (r2);

 \draw[myarrow,dotted] (dn) -- (r1) ;
 \draw[myarrow,dotted] (dn) -- (r2) ;
 \draw[myarrow,dotted] (dn) -- (rn) ;


 \node (r1l) [below=of r1] {};
 \draw[dashed] (r1l) -- (r1l-|f.east);
 \node (r2l) [below=of r2] {};
 \draw[dashed] (r2l) -- (r2l-|f.east);


 \draw[myarrow] (r1) -- (r1-|f.center)  node[sloped,above,near start] {$R'_0$};
 \draw[myarrow] (r2) -- (r2-|f.center)  node[sloped,above,near start] {$R'_1$};
 \draw[myarrow,dotted] (rn) -- (rn-|f.center)  node[sloped,above,near start] {$R'_d$};


  \end{tikzpicture}
  
  \caption{Esquema de funcionament de RoundRobindoop}
  \label{fig:roundrobindoop:esquema}
\end{figure}






Les dades originals són la sèrie temporal $S$ és a dir un conjunt de
parelles de temps i valor, a les quals anomenem mesures. Un sèrie
temporal es pot partir en trossos on cada tros és un subconjunt de
mesures, és a dir una subsèrie temporal. Per tant, cada operació map
rep una subsèrie temporal de l'original: $S'_1 =
\{m_0,\dotsc,m_{o1}\}, S'_2 = \{m_{o1+1},\dotsc,m_{o2}\}, \dotsc, S'_M
= \{\dotsc,m_{k}\}$ on $M$ són el nombre de maps i $o_1 < o_2 < k$.



\todo{} Les dades d'entremig són les sèries temporals dels buffers, és
a dir les mesures pendents de consolidar per a cada subsèrie
resolució.  Així doncs, les dades d'entremig vistes com a conjunt són
un conjunt de dades pendents de consolidar $E=\{ D_{0}, \dotsc, D_r\}$
on cada dada pendent de consolidar és un tuple $D=((\delta,f,n),m)$ on
$(\delta,f,n)$ funciona com a identificador i $m=(t,v)$ com a valor.
És a dir, que indica les mesures $m$ que s'han de consolidar per a una
resolució $\delta$, $f$ i $n\in\glssymbol{not:N}$


Què és aquest n?\todo{}
L'esquema multiresolució $e$ 





\todo{ERROR:cada reduce calcula amb les mesures de delta,f i n}
Les dades finals són les sèries temporals dels discs, és a dir les
mesures consolidades per a cada subsèrie resolució. Així doncs, les
dades finals vistes com a conjunt són un conjunt de dades consolidades
$F=\{ D'_{0}, \dotsc, D'_r\}$ on cada dada consolidada és un tuple
$D'=(\delta,f,m')$ que indica quina mesura $m'=(t,v)$ és i a quin disc
pertany identificat per $\delta$ i $f$.  Per tant, cada operació
reduce, assumint que hi ha un reduce per cada resolució de l'esquema
$e$, calcula un subconjunt de $F$: $F'_0 =
\{(\delta_0,f_0,m'_0),\dotsc,(\delta_0,f_0,m'_{r1})\}, F'_1 =
\{(\delta_1,f_1,m'_{r1+1}),\dotsc,(\delta_1,f_1,m'_{r2})\},\dotsc,F'_d
= \{\dotsc,(\delta_d,f_d,m'_{r})\}$ on $d+1=|e|$ són el nombre de
reduces i $r_1 < r_2 < r$. Aquest nombre total de mesures consolidades
$r$ és afitat ja que cada subconjunt té limitat el cardinal màxim per
l'esquema, $|F'_0| \leq k_1, \dotsc, |F'_d| \leq k_d$, i
per tant $|F|=r+1 \leq k_1 + \dotsb + k_d$.




Definim el map:

map: $S' \times e \mapsto E'$ on $E'= \forall m \in S':
\bigcup\operatorname{classifica}(m,e)$

i aquesta funció de classificació $\operatorname{classifica}(m,e)=\{
\forall (\delta,f,\tau,k) \in e: (\delta,f,\tau+n\delta,t,v) |
\tau+(n-1)\delta < t \leq \tau+n\delta, n\in\glssymbol{not:Z}, t >
\tau \}$.  Atenció que $t > \tau$ indica que $\tau$ és el temps
d'inici de la resolució i per tant no té sentit incloure mesures
anteriors. En aquesta funció de classificació hi ha dues restriccions:
no es tenen en compte els cardinals màxims i s'assumeix que la $f$
treballa sobre $S[\tau+(n-1)\delta ,\tau+n\delta]$. En cas que no
sigui així per a $f$, cal modificar aquests intervals de
classificació. Si es vol tenir en compte els cardinals màxims, cal
adequar bé els $\tau$ de $e$: coneixem $t_k=T(\max(S))$ per tant volem
que $\tau'+k\delta \leq t_k$ però $tau'$ ha de complir
$\tau+n\delta=\tau'$ on $n\in\glssymbol{not:Z}$: resolent aquestes
inequacions es troba el valor de $\tau'$.

%per tant  $\tau+n\delta+k\delta \leq t_k$ ; $\tau+(n+k)\delta \leq t_k$; $n \leq \frac{t_k-\tau}{\delta}-k$;  $n = ROUNDLOW \frac{t_k-\tau}{\delta}-k$   .





El sistema, per exemple Hadoop, agrupa de tots els $E'$ amb el
mateix identificador, és a dir sigui $E$ la unió de tots els $E'$ un
 $E''_{\delta,f,t_b} = \{ (\delta,f,t_b,m) \in E \}$



Definim el reduce:

reduce: $E'' \mapsto R'$. Sigui $E''= \{ (\delta,f,t_b,m_0) ,\dotsc,
(\delta,f,t_b,m_k) \}$. $R'=f(\{m_0,\dotsc,m_k\},i)$ on
$i=[t_b-\delta,t_b]$. De fet no cal l'interval $i$ perquè ja hem
classificat les mesures d'aquest interval a l'operació map, aquí només
l'indiquem per a compatibilitat amb les funcions d'agregació
d'atributs, que tenen la forma $f(S,i)$.




\todo{} En conclusió, el map i el reduce no es corresponen exactament
amb les definicions de les funcions de $\glssymbol{not:sgstm:dmap}$ i
$\glssymbol{not:sgstm:multiresolucio}$, sinó que el map classifica les
mesures de la sèrie temporal segons el buffer que els correspon i el
reduce calcula les mesures consolidades per un disc. És a dir, que un
map i un reduce equivalen a la funcionalitat de la funció
$\glssymbol{not:sgstm:dmap}$ però el conjunt de tots els maps i
reduces equivalen a la funció de
$\glssymbol{not:sgstm:multiresolucio}$, sense expressar-ho en forma de
sèrie temporal total.



\todo{} En realitat, alguns maps i alguns reduces es poden ajuntar en
el mateix procés de càlcul però això no afecta al resultat. Mai, però,
se separa el mateix identificador en diferents reduces.




\subsection{Execució de l'algoritme}

Proposem dues maneres per a executar l'algoritme implementat amb
MapReduce: Hadoop i shell.  \todo{també es pot executar fora de Hadoop
  via pipeline del shell}


A Hadoop:\todo{}
Només farem una configuració de Single Node Setup. 
Després es podria estendre de forma senzilla a una Cluster Setup, on
només caldria decidir com distribuir les dades i els processos de map
i reduce als diferents computadors.


%%% Local Variables:
%%% TeX-master: "main"
%%% End:
