\chapter{Implementació amb para\l.lelisme}

En el capítol \todo{ref al capítol} hem definit la funció de
multiresolució com una funció sobre una sèrie temporal. Aquesta funció
té bàsicament dues parts: un plec sobre un esquema de multiresolució i
mapes sobre la sèrie temporal. Ara implementem
aquesta funció mitjançant computació para\l.lela.


Una tècnica de computació para\l.lela és
MapReduce \parencite{deanghemawat04:mapreduce}, la qual s'adequa bé al
problema ja que es basa en aplicar operacions de mapa (\emph{map}) i
posteriorment plegar-les (\emph{reduce}). Un sistema que es basa
exclusivament en aquesta tècnica és
Hadoop \parencite{hadoop}.

A continuació, en primer lloc, estudiem Hadoop i la tècnica MapReduce.
En segon lloc, implementem usant Hadoop un \gls{SGSTM} anomenat
\emph{RoundRobindoop}. Aquest és un \gls{SGSTM} específic amb
l'objectiu de mostrar una implementació que resolgui la multiresolució
d'una sèrie temporal en temps diferit (\emph{offline}) i computant
para\l.lelament.




\section{Hadoop i MapReduce}


Apache Hadoop, o simplement Hadoop, \parencite{hadoop} és un sistema
de computació distribuïda que permet processar grans volums de dades
amb diferents computadors en para\l.lel. El sistema inclou la gestió
de l'emmagatzematge per a distribuir les dades als diferents
computadors, la qual cosa s'anomena \gls{HDFS}; la gestió dels
diferents processos en els diversos computadors; i el model de
programació para\l.lela, el qual és MapReduce.


MapReduce \parencite{deanghemawat04:mapreduce,lammel08:mapreduce} és
un model de programació per processar algoritmes en para\l.lel. Es
basa en resoldre els algoritmes en dues etapes: primer en una etapa de
\emph{maps} i segon en una etapa de \emph{reduces}.  Aquestes dues
etapes són l'algoritme bàsic i per això s'anomena MapReduce, tot i que
hi ha variacions que afegeixen més etapes.  Els noms de \emph{map} i
\emph{reduce} també s'usen per a les operacions d'alt ordre, com les
mapa (\emph{map}) i plec (\emph{fold} o també \emph{reduce}), que hem
definit en el model dels \gls{SGST}, però
\textcite{lammel08:mapreduce} compara les de MapReduce amb les d'alt
ordre i conclou que no són exactament el mateix; aquí distingirem els
conceptes usant els noms en anglès map i reduce per a MapReduce.


A la~\autoref{fig:mapreduce:esquema}
es mostra l'esquema de funcionament de MapReduce, que és el següent:


\begin{figure}[tp]
  \centering
  \input{imatges/implementacio/mapreduce.tex}
  \caption{Esquema de funcionament de MapReduce}
  \label{fig:mapreduce:esquema}
\end{figure}



\begin{enumerate}

\item Hi ha unes dades originals que es poden partir en
  trossos. Hadoop està orientat a fitxers, mitjançant \gls{HDFS}, i
  per tant cada tros de dades és cadascun dels fitxers que es volen
  processar o bé conjunts de línies d'un fitxer.

\item Cada tros de les dades es processa mitjançant una operació
  map. Cada map es pot computar en para\l.lel i distribuït.

\item Cada operació map ha de retornar un nou conjunt de dades
  formats per parelles d'identificador i valor. Aquests conjunts de
  dades s'ordenen per identificador. 

\item Cada conjunt de dades amb el mateix identificador es processa
  mitjançant una operació reduce. Cada reduce es pot computar en
  para\l.lel i distribuït.

\item Cada reduce ha de retornar un tros del resultat final. És a dir,
  que unint les dades que retornen els reduce s'obtenen les dades
  finals. En l'orientació a fitxers de Hadoop, el resultat final és un
  fitxer, o bé un tros d'un fitxer, per a cada reduce.

\end{enumerate}



Per a resoldre un algoritme amb MapReduce, cal definir l'operació de
map i l'operació de reduce. El map ha de calcular un filtre sobre les
dades, sobretot establir grups de dades, i el reduce ha de calcular
agregacions o resums per a cada grup. MapReduce té una gran similitud
amb l'operació \emph{summarize} dels
\gls{SGBDR} \parencite[cap.~7]{date04:introduction8}, però separada
convenientment en les dues etapes.  A més, MapReduce imposa les
següents restriccions: les dades s'han de poder partir i l'algoritme
s'ha de poder expressar separat en les dues operacions de map i de
reduce.  \textcite{deanghemawat04:mapreduce} mostren exemples
d'algoritmes que es poden expressar amb MapReduce.



Un cop s'ha modelat un algoritme amb MapReduce, aleshores Hadoop ja és
capaç d'executar els maps i els reduces en para\l.lel i distribuïts. A
més, Hadoop també gestiona el compromís dels recursos entre el temps
de distribuir les dades, la quantitat de processos en para\l.lel que
s'han de crear i el temps afegit que suposa cada procés nou.








\section{RoundRobindoop}


RoundRobindoop implementa un \gls{SGSTM} específic que resol la funció
de multiresolució amb el model de programació MapReduce.  Per a
construir RoundRobindoop, primer dissenyem l'algoritme de MapReduce
que s'adequa a la multiresolució. Segon, proposem dues maneres per a
executar RoundRobindoop: amb Hadoop i la shell del sistema.



\subsection{Multiresolució amb MapReduce}

L'algoritme que implementem amb MapReduce és el de la funció de
multiresolució definida a la secció \todo{ref sec: multiresolucio: funcio}. Aquesta funció principalment té dues
parts, una de mapa i una de plec, que com ja s'ha dit no es poden
correspondre exactament amb les operacions de map i de reduce. 
 Així
doncs, dissenyem les operacions de map i de reduce que tenen el mateix
efecte que calcular la funció de multiresolució, en què el resultat
final no és la sèrie temporal total sinó el resultat de totes les
funcions $\glssymbol{not:sgstm:dmap}$, és a dir el resultat final són
les sèries temporals dels discs del model de \gls{SGSTM} la
concatenació dels quals resulta en la sèrie temporal total.



Sigui $S=\{m_0,m_1,\dotsc,m_k\}$ una sèrie temporal, i $e = \{
(\delta_0,f_0,\tau_0,k_0),\ldots, (\delta_d,f_d,\tau_d,k_d)\}$ els
paràmetres d'un esquema de multiresolució, definim l'algoritme
MapReduce que calcula $\operatorname{mapreduce}(S,e) = \{
(\delta_0,f_0,
\glssymbol{not:sgstm:dmap}(S,\delta_0,f_0,\tau_0,k_0)),\dotsc,
(\delta_c,f_c,\glssymbol{not:sgstm:dmap}(S,\delta_c,f_c,\tau_c,k_c))
\}$. És a dir, calcula tots els $\glssymbol{not:sgstm:dmap}$ possibles
i els identifica amb el pas de consolidació $\delta$ i la funció
d'agregació d'atributs $f$, els quals identifiquen les subsèries
resolució assumint que no n'hi ha de repetits.
%i que per tant tenenassociats el cardinal màxim $k$ i un instant de consolidació $\tau$.





L'esquema de funcionament de RoundRobindoop és el de
la~\autoref{fig:roundrobindoop:esquema}, el qual és la implementació
particular de l'esquema de la~\autoref{fig:mapreduce:esquema} per a la
multiresolució.  De forma resumida, RoundRobindoop en l'etapa de map
classifica les mesures en funció de a quin disc i temps resultant es
consolidaran i en l'etapa de reduce calcula la funció d'agregació per
a les mesures que s'hagin de consolidar al mateix disc.  A continuació
expliquem detalladament com són les dades originals ($O$), les
d'entremig ($E$) i les finals ($F$), i finalment definim l'operació de
map i la de reduce.





\begin{figure}[tp]
  \centering

  \begin{tikzpicture}

      \tikzset{
        mynode/.style={rectangle,rounded corners,draw=black, 
          very thick, inner sep=1em, minimum size=3em, text centered,
          groc},
        myarrow/.style={->, shorten >=1pt, thick},
        mylabel/.style={text width=7em, text centered},
        groc/.style={top color=white, bottom color=yellow!50},
        verd/.style={top color=white, bottom color=green!50},
        roig/.style={top color=white, bottom color=red!50},
      }  




 \node[mynode,verd] (m1) {map 1};
 \node (ml1) [below=of m1] {};
 \node[mynode,verd] (m2) [below=of ml1] {map 2};
 \node (ml2) [below=of m2] {};
 \node[mynode,verd,dotted] (mn) [below=of ml2] {map M};


 \node[mynode] (d1) [right=0.5cm of m1] {
   \begin{tabular}{|c|cc|}\hline
     \multirow{2}{*}{$i$} & \multicolumn{2}{|c|}{valor} \\\cline{2-3}
       & \multicolumn{1}{|c|}{t} & v \\\hline
      & & \\
      & &\\\hdashline
      & &\\
      & &\\\hline
   \end{tabular}
 };

 \node[mynode] (d2) [right=0.5cm of m2] {
   \begin{tabular}{|c|cc|}\hline
     \multirow{2}{*}{$i$} & \multicolumn{2}{|c|}{valor} \\\cline{2-3}
       & \multicolumn{1}{|c|}{t} & v \\\hline
      & &\\\hdashline
      & &\\\hline
   \end{tabular}
 };

 \node[mynode,dotted] (dn) [right=1.5cm of mn] {};



 \node[mynode,verd] (r1) [right=0.5cm of d1] {\parbox{1cm}{reduce $\delta_0,f_0$}};
 \node[mynode,verd] (r2) [below=2cm of r1] {\parbox{1cm}{reduce $\delta_1,f_1$}};
 \node[mynode,verd,dotted] (rn) [right=1cm of dn] {\parbox{1cm}{reduce $\delta_d,f_d$}};




 \node[mynode] (o) [above left=1.5cm and 0.5cm of m1, anchor=north east] {
   \begin{tabular}{|c|}\hline
     t v \\\hline
       \\
       \\
     \parbox[c][7cm][s]{0cm}{\vfill} \\
       \\
       \\\hline
   \end{tabular}
 };
 \node [above=0cm of o] {$O$};
 \node[mynode,minimum height=10cm] (f) [above right=of r1, anchor=north west] {
   \begin{tabular}{|c|}\hline
    $\delta\, f$ t v \\\hline
       \\
        \\
     \parbox[c][7cm][s]{0cm}{\vfill}  \\
        \\
        \\\hline
   \end{tabular}
};
 \node [above=0cm of f] {$F$};
 \node [above=0cm of d1] {$E$};




 \draw[dashed] (ml1) -- (ml1-|o.west);
 \draw[dashed] (ml2) -- (ml2-|o.west);

 \draw[myarrow] (o.center|-m1) -- (m1)  node[sloped,above,near end] {$S'_1$};
 \draw[myarrow] (o.center|-m2) -- (m2) node[sloped,above,near end] {$S'_2$};
 \draw[myarrow,dotted] (o.center|-mn) -- (mn) node[sloped,above,near end] {$S'_M$};


 \draw[myarrow] (m1) -- (d1) node[sloped,above,near start] {$E'_1$};
 \draw[myarrow] (m2) -- (d2) node[sloped,above,near start] {$E'_2$};
 \draw[myarrow,dotted] (mn) -- (dn)  node[sloped,above,near start] {$E'_M$};

 \draw[myarrow] (d1.center) -- (r1) node[sloped,above,near end] {$E_{1}^0$};
 \node (d1b) [above=3ex of d1.280] {}; 
 \draw[myarrow] (d1b.center) -- (r2) ;

 \draw[myarrow] (d2.center) -- (r1) node[sloped,above,near end] {$E_{2}^0$};
 \node (d2b) [above=3ex of d2.280] {}; 
 \draw[myarrow] (d2b.center) -- (r2) ;

 \draw[myarrow,dotted] (dn) -- (r1) node[sloped,above,near end] {$E_{1}^1$};
 \draw[myarrow,dotted] (dn) -- (r2);
 \draw[myarrow,dotted] (dn) -- (rn) node[sloped,above,near end] {$E_{d}^d$};


 \node (r1l) [below=of r1] {};
 \draw[dashed] (r1l) -- (r1l-|f.east);
 \node (r2l) [below=of r2] {};
 \draw[dashed] (r2l) -- (r2l-|f.east);


 \draw[myarrow] (r1) -- (r1-|f.center)  node[sloped,above,near start] {$F'_0$};
 \draw[myarrow] (r2) -- (r2-|f.center)  node[sloped,above,near start] {$F'_1$};
 \draw[myarrow,dotted] (rn) -- (rn-|f.center)  node[sloped,above,near start] {$F'_d$};


  \end{tikzpicture}
  
  \caption{Esquema de funcionament de RoundRobindoop}
  \label{fig:roundrobindoop:esquema}
\end{figure}






Les dades originals són la sèrie temporal $S$ és a dir un conjunt de
parelles de temps i valor, a les quals anomenem mesures. Un sèrie
temporal es pot partir en trossos on cada tros és un subconjunt de
mesures, és a dir una subsèrie temporal. Per tant, cada operació map
rep una subsèrie temporal de l'original: $S'_1 =
\{m_0,\dotsc,m_{o1}\}, S'_2 = \{m_{o1+1},\dotsc,m_{o2}\}, \dotsc, S'_M
= \{\dotsc,m_{k}\}$ on $M$ són el nombre de maps i $o_1,o_2\in
\glssymbol{not:N}$, $o_1 < o_2 < k$.



Les dades d'entremig són les sèries temporals dels buffers, és a dir
les mesures pendents de consolidar per a cada subsèrie resolució.
Així doncs, les dades d'entremig vistes com a conjunt són un conjunt
de dades pendents de consolidar $E=\{ D_{0}, \dotsc, D_t\}$ on cada
dada pendent de consolidar és un tuple $D=(i,m)$ on $i=(\delta,f,t_b)$
funciona com a identificador i $m=(t,v)$ com a valor.  És a dir, que
classifica cada mesura $m$ a quines resolucions s'han de consolidar
identificades pel pas de consolidació $\delta$, per la funció
d'agregació d'atributs $f$ i pel temps resultant de consolidació
$t_b$. Per tant, cada operació map resulta en un subconjunt de les
dades d'entremig: $E'_1=\{ (\delta_0,f_0, t_{b0}^0, t_0,v_0),
(\delta_1,f_1, t_{b1}^0, t_0,v_0), \dotsc , (\delta_d,f_d, t_{bd}^0,
t_0,v_0), (\delta_0,f_0, t_{b0}^1, t_1,v_1), \dotsc, (\delta_d,f_d,
t_{bd}^{o1}, t_{o1},v_{o1}) \}$, i $E'_2$ i $E'_M$ de manera similar.
En total, les dades d'entremig tenen un cardinal de $|E|=t+1=|e||S|$
és a dir la quantitat de resolucions de l'esquema multiplicat per la
quantitat de mesures de la sèrie temporal original.


Un cop calculades, les dades d'entremig $E$ s'ordenen i
s'agrupen per identificadors $(\delta,f, t_b)$ idèntics.  Així s'obté
unes dades d'entremig ordenades, de les quals expressem a continuació
cada subconjunt de forma simplificada agrupant per $\delta$ i $f$
sense tenir en comte els $t_b$. Siguin $ t_b, t,v$ variables lliures,
cada subconjunt agrupat de $E$ té la forma:
% Del subconjunt $E'_1$ s'obtenen els subconjunts $O_0^0= \{  (\delta_0,f_0, t_{b0}^0, t,v) \in E'_1 \}, O_0^1= \{  (\delta_0,f_0, t_{b0}^1, t,v) \in E'_1 \},\dotsc,  O_0^d= \{  (\delta_0,f_0, t_{b0}^{r0}, t,v) \in E'_1 \}$
a partir del subconjunt $E'_1$ s'obtenen $E_1^0=\{ (\delta_0,f_0, t_b,
t,v) \in E'_1 \}, E_1^1=\{ (\delta_1,f_1, t_b, t,v) \in E'_1 \},
\dotsc, E_1^d=\{ (\delta_d,f_d, t_b, t,v) \in E'_1 \}$, i de manera
similar s'obtenen els subconjunts agrupats a partir de
$E'_2,\dotsc,E'_d$.  D'aquesta manera cada operació reduce rep, en la
forma simplificada, tots els tuples de $E$ amb el mateix $\delta$ i
$f$: per a $\delta_0$ i $f_0$ rep $E^0 = E_1^0 \cup E_2^0 \cup \dotsb
\cup E_d^0$, per a $\delta_1$ i $f_1$ rep $E^1$, etc.  Com hem dit,
hem expressat aquests conjunts de forma simplificada per a $\delta$ i
$f$ tot i a més hi ha un reduce per a cada $t_b$ diferent; a
continuació per a les dades finals ho expressem de totes dues maneres.



Les dades finals són les sèries temporals dels discs, és a dir les
mesures consolidades per a cada subsèrie resolució. Així doncs, les
dades finals vistes com a conjunt són un conjunt de dades consolidades
$F=\{ D'_{0}, \dotsc, D'_r\}$ on cada dada consolidada és un tuple
$D'=(\delta,f,m')$ que indica quina mesura $m'=(t_b,v')$ és i a quin
disc pertany identificat per $\delta$ i $f$.  Per tant, cada operació
reduce calcula un subconjunt de $F$: $F_0^0
=\{(\delta_0,f_0,t_{b0}^0,v_0^0)\}, F_0^1
=\{(\delta_0,f_0,t_{b0}^1,v_0^1)\}, \dotsc, F_0^{r0}
=\{(\delta_0,f_0,t_{b0}^{r0},v_0^{r0})\}, F_1^0= \dotsc, F_1^{r1}=
\dotsc, F_d^0= \dotsc, F_d^{rd}=
\{(\delta_d,f_d,t_{bd}^{rd},v_d^{rd})\}$ on el nombre de mesures
consolidades per cada disc és afitat als cardinals màxims, $r_0 +1
\leq k_0, r_1 +1 \leq k_1, \dotsc r_d +1 \leq k_d$, i per tant el
nombre total de reduces està afitat a $|F| \leq k_0+k_1\dotsb+k_d$.
Per a simplificar la~\autoref{fig:roundrobindoop:esquema} s'han
agrupat els reduce per $\delta$ i $f$, és a dir $F'_0 =
\{(\delta_0,f_0,t_{b0}^0,v_0^0),(\delta_0,f_0,t_{b0}^1,v_0^1),\dotsc,
(\delta_0,f_0,t_{b0}^{r0},v_0^{r0})\}$, etc.\ i per tant $d+1= |e|$
són el nombre total de reduces agrupats.



L'operació map calcula les dades d'entremig a partir de les dades
originals i un esquema multiresolució, treballa en subconjunts de les
dades per a així poder-se computar para\l.lelament.
\begin{definition}[Operació Map]
  Sigui $S'=\{m_0,\dotsc,m_{o1}\}$ una subsèrie temporal de les dades
  originals, $e=\{ (\delta_0,f_0,\tau_0,k_0),\ldots,
  (\delta_d,f_d,\tau_d,k_d)\}$ un esquema de multiresolució i
  $E'=\{(\delta_0,f_0, t_{b0}^0, t_0,v_0),\dotsc, \dotsc,
  (\delta_d,f_d, t_{bd}^{o1}, t_{o1},v_{o1}) \}$ un subconjunt de les
  dades d'entremig abans de ser ordenades, l'operació map de
  l'algoritme MapReduce és $E'=\operatorname{map}(S',e)$ on $E'=
  \forall m \in S': \bigcup\operatorname{classifica}(m,e)$.

  La funció $\operatorname{classifica}$ indica per a cada mesura a quins
  discs s'ha de consolidar: $\operatorname{classifica}(m,e)=\{ \forall
  (\delta,f,\tau,k) \in e: (\delta,f,\tau+n\delta,t,v) |
  \tau+(n-1)\delta < t \leq \tau+n\delta, n\in\glssymbol{not:Z}, t >
  \tau \}$. Cal tenir en compte que $t > \tau$ indica que $\tau$ és el temps
  d'inici de la resolució i per tant no té sentit incloure mesures
  anteriors.
\end{definition}






Hi ha dues restriccions a la funció $\operatorname{classifica}$ que
hem definit: 
\begin{itemize}

\item S'assumeix que la $f$ treballa sobre l'interval de la sèrie
  original $S(\tau+(n-1)\delta ,\tau+n\delta]$. En cas que no sigui
  així per a la $f$ escollida, caldria modificar aquests intervals de
  classificació. A continuació d'aquest apartat contextualitzem aquest
  problema de les $f$.

\item No es tenen en compte els cardinals màxims. Si es volen tenir en
  compte, cal adequar bé els $\tau$ inicials. Així sigui $e$ l'esquema
  de multiresolució original, per a tenir en compte els cardinals
  màxims s'haurà d'usar un nou esquema $e'$ en què cada $\tau$
  original sigui canviat a un altre temps de consolidació múltiple
  $\tau'= \tau+n\delta$ (1) on $n\in\glssymbol{not:Z}$.  \emph{Càlcul
    de $n$:} es coneix $t_k=T(\max(S))$ i per a tenir en compte els
  cardinals s'ha de complir que $\tau'+k\delta \leq t_k$ (2), és a dir
  que les mesures entre $[\tau'+k\delta,t_k]$ encara no es poden
  consolidar.  Substituint la (1) a la (2) $\tau+n\delta+k\delta \leq
  t_k$, operant $\tau+(n+k)\delta \leq t_k$ i $n \leq
  \frac{t_k-\tau}{\delta}-k$ d'on es conclou que $n = \left\lfloor
    \frac{t_k-\tau}{\delta}-k \right\rfloor$ .  A més a més, si no es
  considera vàlid $\tau'<\tau$, és a dir que no es volen mesures abans
  del temps d'inici original, aleshores $n$ com a mínim pot valdre
  zero.

\end{itemize}



\begin{example}[Classificació d'una mesura en les resolucions]
  Sigui l'esquema de multiresolució
  $e=\{(\delta_0=2,f_0,\tau_0=0,k_0=4),(\delta_1=5,f_1,\tau_1=10,k_1=3)\}$
  i la mesura $m=(25,1)$, aquesta és classificada per a consolidar-se
  en les dues resolucions $\operatorname{classifica}(m,e)=\{
  (2,f_0,t_{b0},25,1), (5,f_1,t_{b1},25,1) \}$ on
  $\tau_0+(n-1)\delta_0 < 25 \leq \tau_0+n\delta_0,
  n\in\glssymbol{not:Z}$ i $t_{b0}=\tau_0+n\delta_0 = 26$, i de manera
  semblant $t_{b1}= 25$.

  Ara es volen tenir en compte els cardinals màxims, sigui
  $t_k=T(\max(S))=35$ el temps de la mesura màxima de la sèrie
  temporal original. Aleshores cal canviar l'esquema de multiresolució
  $e'=\{(\delta_0=2,f_0,\tau'_0,k_0=4),(\delta_1=5,f_1,\tau'_1,k_1=3)\}$
  on $\tau'_0=26$ i $\tau'_1=20$. La classificació esdevé
  $\operatorname{classifica}(m,e')=\{ (5,f_1,25,25,1) \}$ on no hi ha
  la resolució $\delta_0,f_0$ perquè $25< \tau'_0$.
\end{example}





Un cop s'han obtingut les dades d'entremig $E$, el sistema com per
exemple Hadoop agrupa els tuples de $E$ amb el mateix identificador i
els processa a un mateix reduce. És a dir, sigui $E$ la unió de tots
els $E'$ calculats pels map, un subconjunt de les dades ordenades és
$E''_{\delta,f,t_b} = \{ (\delta,f,t_b,m) \in E \}$.  L'operació
reduce calcula les dades finals a partir de les dades d'entremig
ordenades, treballa en subconjunts de les dades per a així poder-se
computar para\l.lelament.
\begin{definition}[Operació Reduce]
  Sigui $E''= \{ (\delta,f,t_b,m_0) ,\dotsc, (\delta,f,t_b,m_k) \}$ un
  subconjunt de les dades d'entremig ordenades i $F'=\{
  (\delta,f,t_b,v) \}$ un subconjunt de les dades finals, l'operació
  reduce de l'algoritme MapReduce és $F'=\operatorname{reduce}(E'')$
  on $F'= (\delta,f,t_b,v)$ i $v= V( f(\{m_0,\dotsc,m_k\},i))$ i
  $i=[t_b-\delta,t_b]$.
\end{definition}

L'expressió de l'interval $i$ es pot ometre ja que l'operació map ja
ha classificat les mesures d'aquest interval, tot i així l'indiquem
per a seguir la forma genèrica $f(S,i)$ de les funcions d'agregació
d'atributs de la definició. A continuació d'aquest apartat
contextualitzem aquest problema de les $f$.


En conclusió, el map i el reduce no es corresponen exactament
amb les definicions de les funcions de $\glssymbol{not:sgstm:dmap}$ i
$\glssymbol{not:sgstm:multiresolucio}$ \todo{ref a la secció?}, sinó
que el map classifica les mesures de la sèrie temporal segons el
buffer que els correspon i el reduce calcula les mesures consolidades
per un disc. És a dir, que un map i un reduce equivalen a la
funcionalitat de la funció $\glssymbol{not:sgstm:dmap}$ però el
conjunt de tots els maps i reduces equivalen a la funció de
$\glssymbol{not:sgstm:multiresolucio}$, sense expressar-ho en forma de
sèrie temporal total.



\subsubsection{Quant a les $f$ a RoundRobindoop}
\label{sec:mapreduce:f}

Al model de \gls{SGSTM} hem definit de forma genèrica les funcions
d'agregació d'atributs com a $m=f(S,i)$ (v. def.\todo{ref}). Aquestes funcions
principalment realitzen dues operacions: una selecció sobre la sèrie
temporal i una agregació de les mesures seleccionades. 

A RoundRobindoop, l'operació de selecció es duu a terme a l'etapa de
map i en canvi l'agregació, a l'etapa de reduce.  En l'algoritme de
MapReduce definit per a RoundRobindoop usem el model de $f$ descrit
anteriorment, però per a implementar correctament aquestes funcions
cal interpretar-ne el significat per a l'etapa de map i per a la de
reduce. És a dir, cada $f$ hauria de tenir dos components: un amb les
operacions de selecció per a ser usades en els map i l'altre amb les
operacions d'agregació per als reduce.


Així doncs, caldria afegir en els paràmetres de RoundRobindoop
l'operació de selecció d'interval per a cada $f$ que s'utilitzi. Però
això complica la resolució de l'algoritme de MapReduce. Per exemple,
resoldre l'interval temporal \gls{zohe}
--$S[t_0,t_f]^{\glssymbol{not:zohe}} = S(t_0,t_f] \cup \{
(t_f,V(\inf(S[t_f,+\infty))) \}$ (v.~def.\todo{ref a la def})--
implica conèixer la mesura següent a un $t_f$ i per tant treballar
sobre tota la sèrie temporal original, cosa que no és possible perquè
en les etapes map només es treballa sobre un subconjunt de la sèrie
temporal original. Això no obstant, per al RoundRobindoop definit, si
considerem que la sèrie temporal és de temps real aleshores en l'etapa
map podem fer la selecció prèvia per l'interval
$S(t_b-\delta,t_b+\delta]$, és a dir assumim que hi ha mesura a
$[t_b,t_b+\delta]$, i a l'etapa reduce ja es calcularà correctament
$f(S,[t_b-\delta,t_b])$. 


Recordem que en l'algoritme de RoundRobindoop definit hem assumit que
l'interval de selecció en l'etapa map sempre és $(t_b-\delta,t_b]$ i
en l'etapa reduce usem el model genèric d'agregació $f(S,i)$ tot i que
les mesures ja han estat seleccionades. Per tant, la interpretació en
l'etapa map no és vàlida per a totes les $f$.

Per tal d'ampliar l'etapa map, proposem una nova funció de
classificació que admeti ampliar l'interval de selecció. Si en la
classificació definida cada mesura es classificava en un i només un
$t_b$ per a cada resolució, en la nova funció de classificació es pot
escollir a quants $t_b$ es classifica cada mesura.  Sigui
$\operatorname{classifica}(m,e)$ la funció de classificació original i
sigui $l,g\in\glssymbol{not:N}$ les quantitats desitjades, la nova funció
de classificació és $\operatorname{classifica}'(m,e,l,g)=\{ \forall
(\delta,f,\tau,k) \in e: (\delta,f,\tau+(n-G_g)\delta,t,v), \dotsc,
(\delta,f,\tau+(n-G_0)\delta,t,v), (\delta,f,\tau+n\delta,t,v),
(\delta,f,\tau+(n+L_0)\delta,t,v), \dotsc,
(\delta,f,\tau+(n+L_l)\delta,t,v) | \tau+(n-1)\delta < t \leq
\tau+n\delta, n\in\glssymbol{not:Z}, t > \tau \}$ on
$L=\{1,2,\dotsc,l\}$ i $G=\{1,2,\dotsc,g\}$. El paràmetre $l$
permet classificar una mesura en temps posteriors i el paràmetre $g$
en temps anteriors; si ho observem des del punt de vista de la
selecció d'interval $S(t_b-(l+1)\delta,t_b+g\delta]$, el paràmetre $l$
permet estendre l'interval cap a l'esquerra i $g$ cap a la dreta.

\begin{example}[Classificació d'una mesura per \gls{zohe}]
  \label{ex:mapreduce:fzohe} 
  Com ja hem comentat, per a les funcions d'agregació d'atributs de la
  família \gls{zohe} s'ha d'aproximar l'interval temporal \gls{zohe} a
  una selecció en l'interval $S(t_b-\delta,t_b+\delta]$. És a dir, que
  la funció de classifica ha de retornar dues classificacions per a
  cada mesura, una amb $t_b$ i l'altra amb $t_b-\delta$. Per tant, per
  aquesta família $g=1$ i $l=0$.

  Sigui l'esquema de multiresolució
  $e=\{(\delta_0=2,f_0,\tau_0=0,k_0=4),(\delta_1=5,f_1,\tau_1=10,k_1=3)\}$
  i la mesura $m=(25,1)$, aquesta és classificada per a consolidar-se
  en les dues resolucions i en els dos instants per a cada un:
  $\operatorname{classifica}'(m,e,l=0,g=1)=\{
  (2,f_0,t_{b0}-g\delta_0,25,1), (2,f_0,t_{b0},25,1),
  (5,f_1,t_{b1}-g\delta_1,25,1), (5,f_1,t_{b1},25,1) \}$ on $t_{b0}=
  26$, $t_{b0}-g\delta_0= 24$, $t_{b1}= 25$ i $t_{b1}-g\delta_1= 20$.
  És a dir, es pot interpretar per a $\delta_0$ que quan es consolidi
  l'instant $24$ s'ha de fer la selecció $S(22,26]$ i per l'instant
  $26$ s'ha de fer la selecció $S(24,28]$, intervals en els quals hi
  ha la mesura $(25,1)$.

  A continuació, en l'apartat d'execució de l'algoritme, utilitzarem un exemple
  amb aquests processos de classificació.
\end{example}






En resum, el model de programació MapReduce limita les capacitats dels
\gls{SGSTM}, sobretot pel que fa a les funcions d'agregació
d'atributs. 






\subsection{Execució de l'algoritme}

\lstMakeShortInline[style=sh]{@}

Hadoop s'encarrega de l'execució de l'algoritme de MapReduce i de la
gestió de les dades d'entrada i de sortida.  Per a implementar-lo, cal
dissenyar un programa per al map i un programa per al reduce, els
quals reben de Hadoop els subconjunts de dades escaients i han de
retornar els subconjunts també escaients.  

Es pot utilitzar diferents llenguatges de programació a l'hora
d'implementar l'algoritme de MapReduce, hem escollit el llenguatge
Python \parencite{python:doc2}.  Implementem l'algoritme de MapReduce
que hem definit, RoundRobindoop, en un mateix programa que anomenem
@rrdoop.py@. El programa té un paràmetre que permet escollir l'etapa,
@rrdoop.py -map@ o @rrdoop.py -reduce@. A més també hi ha un paràmetre
per a definir l'esquema de multiresolució utilitzat, %
@rrdoop.py -map -schema e@.

El programa es comunica amb Hadoop mitjançant l'entrada estàndard
(stdin) per a rebre dades i mitjançant la sortida estàndard (stdout)
per a retornar els resultats.  Gràcies a la generalització del
programa amb comunicació per stdin i stdout, també es pot executar
l'algoritme de MapReduce al shell del sistema operatiu, cosa que
facilita l'experimentació amb l'algoritme.  Així, a continuació,
primer mostrem l'execució pas a pas de @rrdoop.py@ al shell i després
mostrem l'execució a Hadoop.



\subsubsection{Execució a la shell}

El~\autoref{lst:rrdoop:shell} és l'execució de
@rrdoop.py@ al shell del sistema operatiu. Només hi ha un procés map i
un procés reduce. Es comuniquen les dades a través de pipes (@|@) de la
shell i d'un procés d'ordenació (@sort@) que emula el procés
d'ordenació per identificador que faria Hadoop. A més, també s'emula
el procés de lectura (@cat@) de les dades originals.

\begin{lstlisting}[style=sh,caption=Execució a la shell de
  rrdoop.py,label=lst:rrdoop:shell]
cat original.csv | rrdoop.py -map -schema e.pickle -mapg 1 | sort -k1,1 | rrdoop.py -reduce -schema e.pickle
\end{lstlisting}


Les dades d'entrada són un fitxer, que també podrien ser fitxers de
dades, de les quals Hadoop en processa conjunts de línies a cada
procés map. Aquestes dades no cal que siguin ordenades i cal tenir en
compte que es poden trencar per qualsevol línia, tot i que Hadoop
permet configurar etapes que defineixin com s'han de partir els
fitxers.  Al~\autoref{lst:rrdoop:stdin} mostrem les dades d'entrada
emmagatzemades en el fitxer @original.csv@, que es corresponen
amb la sèrie temporal ja utilitzada
al~\autoref{lst:roundrobinson:ex1}.  Aquest fitxer de dades té format
de \gls{CSV}, com ja s'ha vist al~\autoref{lst:pytsms:storage} en les
funcionalitats complementàries per a l'emmagatzematge de Pytsms.
\begin{lstlisting}[style=file,caption=Dades d'entrada @original.csv@,label=lst:rrdoop:stdin]
1,6
8,5
5,2
10,0
14,1
19,6
26,6
29,0
22,11
\end{lstlisting}


El fitxer @original.csv@ es transmet a través de @cat@ i pipe a
l'stdin del procés de map %
@rrdoop.py -map -schema e.pickle -mapg 1@.  El procés de map té un esquema de
multiresolució com a paràmetre, @rrdoop.py@ a través del paràmetre
@-schema@ admet una sèrie temporal multiresolució en format Pickle,
com s'ha vist al~\autoref{lst:roundrobinson:storage}, l'esquema de la
qual serà el que s'utilitzi. En aquest cas, @e.pickle@ es correspon
amb el fitxer @mrd.pickle@ del~\autoref{lst:roundrobinson:storage} i
per tant amb l'esquema de multiresolució
del~\autoref{lst:roundrobinson:ex1}:
$e=\{(\delta_0=5,k_0=4,f_0=\glssymbol{not:sgstm:meanzohe},\tau_0=0),(\delta_1=10,k_1=2,f_1=\glssymbol{not:sgstm:maxzohe},\tau_1=0)\}$.


En aquest exemple d'esquema de multiresolució s'usen funcions
d'agregació d'atributs de la família \gls{zohe}. Com ja hem comentat a
l'\autoref{ex:mapreduce:fzohe}, s'ha de canviar la selecció que
l'etapa map duu a terme. A tal efecte RoundRobindoop admet un
paràmetre @-mapg@ per a indicar l'expansió de la classificació cap a
la dreta. Aproximem l'interval temporal \gls{zohe} a una selecció en
l'interval $(t_b-\delta,t_b+\delta]$, és a dir que hem d'expandir un
interval @-mapg 1@.  RoundRobindoop també admet un paràmetre @-mapl@
per a l'expansió cap a l'esquerra.


El procés de map retorna el resulta a través de l'stdout, el qual es
mostra al~\autoref{lst:rrdoop:sortidamap} i es correspon amb les dades
d'entremig de MapReduce. El format és el requerit per Hadoop, és a dir
cada línia és una parella d'identificador i valor separats per un
tabulador. L'identificador és $(\delta,\tau,t_b)$ però escrit en el
format $\delta$/$\tau$--$t_b$ i el valor és $(t,v)$ escrit separat per
un espai. Es pot observar com es comença classificant la primera
mesura $(1,6)$ en l'instant de consolidació $t_b=10$ per $\delta_1$ i
$t_b=5$ per $\delta_0$.  A continuació la mesura $(8,5)$ es classifica
a l'instant de consolidació $t_b=10$ per $\delta_1$ i en els $t_b=10$
i $t_b=5$ per $\delta_0$, en aquest darrer cas s'aplica l'aproximació
de la selecció \gls{zohe} per l'interval $(t_b-\delta,t_b+\delta]$;
cal destacar que en els casos anteriors no s'aplica perquè resultaria en
un $t_b<= \tau$.  I així per a totes fins a la darrera mesura
$(22,11)$.
\begin{lstlisting}[style=stdout,caption=Sortida del procés map,label=lst:rrdoop:sortidamap]
10/maximum_zohe-10	1 6.0
5/mean_zohe-5	1 6.0
10/maximum_zohe-10	8 5.0
5/mean_zohe-10	8 5.0
5/mean_zohe-5	8 5.0
10/maximum_zohe-10	5 2.0
5/mean_zohe-5	5 2.0
10/maximum_zohe-10	10 0.0
5/mean_zohe-10	10 0.0
5/mean_zohe-5	10 0.0
10/maximum_zohe-20	14 1.0
10/maximum_zohe-10	14 1.0
5/mean_zohe-15	14 1.0
5/mean_zohe-10	14 1.0
10/maximum_zohe-20	19 6.0
10/maximum_zohe-10	19 6.0
5/mean_zohe-20	19 6.0
5/mean_zohe-15	19 6.0
10/maximum_zohe-30	26 6.0
10/maximum_zohe-20	26 6.0
5/mean_zohe-30	26 6.0
5/mean_zohe-25	26 6.0
10/maximum_zohe-30	29 0.0
10/maximum_zohe-20	29 0.0
5/mean_zohe-30	29 0.0
5/mean_zohe-25	29 0.0
10/maximum_zohe-30	22 11.0
10/maximum_zohe-20	22 11.0
5/mean_zohe-25	22 11.0
5/mean_zohe-20	22 11.0
\end{lstlisting}


A continuació el procés d'ordenació @sort -k1,1@ ordena per
identificadors, el qual es mostra
al~\autoref{lst:rrdoop:sortidasort}. Hadoop agruparia els mateixos
identificadors i els transmetria a l'stdin d'un procés de reduce.
Observem per exemple la primera resolució @10/maximum_zohe-10@ que
conté les mesures en els instants de temps 10, 14, 1 ,19, 5 i 8;
l'agregació posterior haurà de treballar en l'interval \gls{zohe}
[0,10] i per tant ara queda clar que les mesures de 14 i 19 no són
necessàries, però això no ho podíem resoldre en l'etapa de map.
\begin{lstlisting}[style=stdout,caption=Sortida del procés d'ordenació,label=lst:rrdoop:sortidasort]
10/maximum_zohe-10	10 0.0
10/maximum_zohe-10	14 1.0
10/maximum_zohe-10	1 6.0
10/maximum_zohe-10	19 6.0
10/maximum_zohe-10	5 2.0
10/maximum_zohe-10	8 5.0
10/maximum_zohe-20	14 1.0
10/maximum_zohe-20	19 6.0
10/maximum_zohe-20	22 11.0
10/maximum_zohe-20	26 6.0
10/maximum_zohe-20	29 0.0
10/maximum_zohe-30	22 11.0
10/maximum_zohe-30	26 6.0
10/maximum_zohe-30	29 0.0
5/mean_zohe-10	10 0.0
5/mean_zohe-10	14 1.0
5/mean_zohe-10	8 5.0
5/mean_zohe-15	14 1.0
5/mean_zohe-15	19 6.0
5/mean_zohe-20	19 6.0
5/mean_zohe-20	22 11.0
5/mean_zohe-25	22 11.0
5/mean_zohe-25	26 6.0
5/mean_zohe-25	29 0.0
5/mean_zohe-30	26 6.0
5/mean_zohe-30	29 0.0
5/mean_zohe-5	10 0.0
5/mean_zohe-5	1 6.0
5/mean_zohe-5	5 2.0
5/mean_zohe-5	8 5.0
\end{lstlisting}


Finalment, el procés de reduce %
@rrdoop.py -reduce -schema e.pickle@ obté de l'stdin les dades
del~\autoref{lst:rrdoop:sortidasort} i retorna les dades finals per
l'stdout que es mostren al~\autoref{lst:rrdoop:sortidashell}.  Hadoop
emmagatzemaria aquestes dades en un fitxer o fitxers de dades.
Aquestes dades tenen el format $\delta$/$f$ $t_b$ $v$ on $(t_b,v)$ és
la mesura consolidada per a la resolució identificada per
$(\delta,f)$. 

\begin{lstlisting}[style=stdout,caption=Sortida de rrdoop.py -reduce,label=lst:rrdoop:sortidashell]
10/maximum_zohe	10 6.0
10/maximum_zohe	20 11.0
10/maximum_zohe	30 None
5/mean_zohe	10 3.0
5/mean_zohe	15 2.0
5/mean_zohe	20 7.0
5/mean_zohe	25 8.0
5/mean_zohe	30 None
5/mean_zohe	5 2.8
\end{lstlisting}

Així aquest resultat és el mateix que el de les consultes $\glssymbol{not:sgstm:seriedisc}(M,5,\glssymbol{not:sgstm:meanzohe})$ i $\glssymbol{not:sgstm:seriedisc}(M,10,\glssymbol{not:sgstm:maxzohe})$ del~\autoref{lst:roundrobinson:ex1} però amb les particularitats següents:

\begin{itemize}
\item RoundRobindoop no té en compte els cardinals màxims $k$ de les resolucions. Hi ha la mesura consolidada a l'instant $t_b=5$ per a la resolució $\delta_0=5$ que ja hauria d'haver estat eliminada per complir amb $k_0=4$.

\item RoundRobindoop no té en compte el temps màxim de la sèrie
  temporal original per a conèixer les mesures que encara no són
  consolidables. Hi ha la mesures en l'instant $t_b=30$ per a
  $\delta_0=5$ i $\delta_1=10$ que encara no podien ser calculades
  perquè $T(\max(S))=29$, de fet tenen valor nul (\emph{None}) a causa
  que l'interval \gls{zohe} no es pot calcular.

\item Així doncs, hi ha 9 mesures consolidades finals però 3 s'han de
  descartar. Per tant, per a la resolució $\delta_0=5$ hi ha 4 mesures
  i es compleix $4 \leq k_0=4$, i per a la resolució $\delta_1=10$ hi ha 2
  mesures i es compleix $2 \leq k_1=3$.
\end{itemize}




\subsubsection{Execució a Hadoop}


El~\autoref{lst:rrdoop:hadoop} mostra els passos d'execució de @rrdoop.py@ a
Hadoop. Primer cal copiar la sèrie temporal original al \gls{HDFS},
després s'executa l'algoritme MapReduce i finalment es recupera el
resultat del \gls{HDFS}.


\begin{lstlisting}[style=sh,caption=Execució a Hadoop de
  rrdoop.py,label=lst:rrdoop:hadoop]


hadoop dfs -copyFromLocal original.csv /user/aleix/matriu0.csv


hadoop jar /usr/lib/hadoop/contrib/streaming/hadoop-streaming*.jar -file rrdoop.py -mapper 'rrdoop.py -map -mapg 1' -reducer 'rrdoop.py -reduce' -input /user/aleix/matriu0.csv -output /user/aleix/matriu


hadoop dfs -copyToLocal /user/aleix/matriu/part-00000 final.csv

\end{lstlisting}\todo{simplificar alguns path, no cal tant detall aquí}
\todo{falta afegir mapg i schema}

El resultat és el mateix que per a l'execució a la shell, és a dir
el~\autoref{lst:rrdoop:sortidashell}.  Hadoop gestiona automàticament
la distribució i la quantitat dels processos map i reduce. Així,
alguns dels map o reduces es poden ajuntar en el mateix procés, per
exemple els reduce poden rebre tant els subconjunts $E^0$ o $E''$ de
la secció anterior, però mai se separa el mateix identificador en
diferents reduces. De fet, aquest és el cas quan s'executa a la shell,
on només hi ha un procés map i un de reduce.



Per tal d'observar de manera senzilla l'execució de l'algoritme a
Hadoop hem realitzat una configuració anomenada \emph{Single Node
  Setup}, és a dir on només hi ha un computador que processa.  Un cop
verificat es podria estendre a una configuració de \emph{Cluster
  Setup}, en què hi hagués més computadors on distribuir les dades i
els processos.




% \subsubsection{Anàlisi de temps}


%Estaria bé comparar també amb pytsms, encara que s'ha de dir que no tenen res a veure perquè a pytsms no hem tingut gens en compte l'eficiència en el temps

% Per al temps s'hauria d'executar com a mínim 10 vegades cada experiment


% Analitzem el temps que triga en executar-se l'algoritme de MapReduce,
% tant en la shell com a Hadoop. En aquest darrer cas no incloem el
% temps de treballar amb el \gls{HDFS}.


% \begin{verbatim}
% * shell

% time cat matriu0.csv | ./rrdoop.py -map | sort -k1,1 | ./rrdoop.py -reduce > provant.csv::

%  real   0m21.639s
%  user   0m21.513s
%  sys    0m0.864s


% * hadoop

% time hadoop jar /usr/lib/hadoop/contrib/streaming/hadoop-streaming*.jar -file rrdoop.py -mapper 'rrdoop.py -map' -reducer 'rrdoop.py -reduce' -input /user/aleix/matriu0.csv -output /user/aleix/matriu::

%  real   0m28.314s
%  user   0m1.640s
%  sys    0m0.152s
% \end{verbatim}











\lstDeleteShortInline{@}



%%% Local Variables:
%%% TeX-master: "main"
%%% End:
