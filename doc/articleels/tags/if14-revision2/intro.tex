\section{Introduction}

Data collection processes proliferate due to the emergence of embedded
systems and sensor networks.  This provides opportunity to collect
large amounts of data. To be useful, these data should be analysed and
processed by information systems. A typical processing, for instance,
is to detect eventual sensor failures or malfunctions and, if it is
possible, to reconstruct the faulty data. The acquired data instances
are bound to a timestamp, therefore correctness criteria must include
both data value and its timestamps. The sequences of data values
collected at specific timestamps are formalised as \emph{time series}.

Time series are defined as a collection of chronological observations.
In general, time series are acquired continuously from a phenomena
monitoring. The observations can be recorded at regular intervals,
such as hourly or daily, resulting in equi-time spaced data; or at
irregular intervals, such as recording when a pump is open or closed,
resulting in non equi-time spaced data. Time series data are often
voluminous \cite{fu11,keogh08:isax}, thus efficiently storing and
accessing them can be complex. Moreover, this is specially critical
when developing small embedded systems, whose resources (capacity,
energy or processing power) are constrained \cite{yaogehrke02}.
Additionally, non equi-time spaced data increases the difficulty of
processing.

The literature describes several attempts to build systems devoted to
manage and store time series data. These systems are generically known
as \emph{Time Series Data Base Management Systems} (\acro{TSMS}),
\cite{dreyer94,last01}. However, as shown below, most of them exhibit
some drawbacks when trying to solve this challenging issue.

Time series can be stored and managed by \emph{relational database
management systems} that are usually queried using \emph{Structured Query
Language} (\acro{SQL}) .
%
However, some authors
\cite{dreyer94,schmidt95,stonebraker09:scidb,zhang11} notice that the
use of \acro{SQL} systems as a time series backend suffers from some
drawbacks.

\acro{NoSQL} or \acro{NewSQL} products are being developed in order to
increase the performance and flexibility of \acro{SQL} systems
\cite{atzeni13:relational_model_dead,stonebraker10,stonebraker09:scidb,zhang11}.
%
It is natural to consider them to store time series data. Even so, the
continuous acquisition nature of the time series poses an issue when
trying to store and analyse all the data \cite{keogh97}.

Compression techniques for time series are applied in two distinct
ways to face the challenges posed by time series data. First, to get
an approximation to the original signal in order to compute similarity
or pattern search analysis \cite{fu11,keogh01,last01}. Second, as a
compression and aggregation approach to store massive \emph{data streams}
\cite{cormode08:pods,bonnet01}.
%
Nonetheless, handling time series like data streams neither considers
adequately the time dimension nor computes the evolution of aggregated
parameters along time, which is interesting for monitoring purposes.

\emph{RRDtool} \cite{rrdtool} is a system that stores time series
aggregated in different resolutions. This allows to compact the data
and facilitates faster visualisations.
%
Even though, \emph{RRDtool} is a very specific application and
aggregation operations are limited to network monitoring.




\subsection{Contributions}

%TSMS

This paper formalises a model for \acro{TSMS} that stores and manages
time series data.
%
This model exhibits several interesting characteristics:
\begin{itemize}
\item It organises the data in an aggregated way and it allows to
  store time series using different time resolutions. This
  characteristic is known as \emph{multiresolution}. It is designed to
  satisfy the requirements of bounded storage computers such as sensor
  systems.

\item It is a \emph{lossy storage} solution. Multiresolution allows for a
  lossy storage solution that selects only the relevant data. This is
  close to multimedia lossy compression methods where meaningless data
  is discarded in favour of size. 

\item It considers the time sampling irregularities of time series and
  operates coherently with the time dimension of time series.

\item It offers a degree of genericity to cope with the semantic
  characteristics of the actual data. 

  Multiresolution requires to aggregate several data instances into a
  single one. This is abstracted through an \emph{aggregation function} that
  is tied to the specific semantics of the actual data. Because of
  this, aggregation functions are set as an independent object of the
  main model.  Users can define new aggregation methods which are
  better suited for specific fields.

  The model also formalises the concept of time series \emph{representation
  function}.  This allows users to define different operators
  considering the behaviour of time series in different contexts. This
  is important to manage the specific semantics of the stored time
  series. 

\item It is soundly formalised using set algebra and, particularly,
  relational algebra.
\end{itemize}

The most salient characteristic of our model is that it actually stands
stands for a \emph{Multiresolution Time Series Data Base Management System}
(\acro{MTSMS}).

Our model shares some of its characteristics with other known
approaches.
%
The multiresolution concept is inspired by a thoroughly analysis of
\emph{RRDtool}~\cite{rrdtool}. However, we provide a sound
formalisation that lacks in~\cite{rrdtool} and a degree of genericity
unavailable in \emph{RRDtool}. Under our model \emph{RRDtool}-like
specific counter time series aggregations can be defined based on this
facility.
%
We formalise time series following the way bitemporal data is
formalised for relational \acro{DBMS}.
%
The model allows to favour more recent data over older one. This is in
common in some approaches, like that of Cormode et
al.~\cite{cormode08:pods}.

It should be remarked that the only goal of the model formalised here
is to manage time series data. In practical applications it would be
usual to complement this model with a standard database system to
manage all the remaining data if needed. For instance, time series'
metadata such as units of values, sensor localisation or
classification tags would be stored in a standard \acro{DBMS}.


\subsection{Outline}

This manuscript is organised as
follows. Section~\ref{sec:related-work} introduces previous work that
concerns \acro{TSMS} and \acro{MTSMS}.  The motivation for
multiresolution is shown in Section~\ref{sec:features}.  The model is
described in two steps.
%
First, in Section~\ref{sec:model:TSMS} we formalise a \acro{TSMS}
model that is devoted to time series basic elements and operations.
%
Second, in Section~\ref{sec:MTSMS} we formalise a \acro{MTSMS} model
that adds multiresolution capabilities to the \acro{TSMS} model.
%
In Section~\ref{sec:implementation} we describe an implementation of
the integrated \acro{TSMS} and \acro{MTSMS} model.  Section~\ref{sec:example} is
devoted to a real data multiresolution database example.  Finally,
Section~\ref{sec:concl-future-work} offers some conclusions.




\section{Previous work}
\label{sec:related-work}

For the sake of completeness here we describe some previous work
related to time series storage. It is organised in three subsections.
First, we introduce some previous database management systems
approaches for time series. Second, we explain how compression
techniques are applied to leverage time series storage. Third, we
review time series storage systems based on the data streams paradigm.


\subsection{Database approaches}

According to some authors, \acro{TSMS} should be considered as a
specialised relational \acro{DBMS}~\cite{last01}.  Segev and
Shoshani~\cite{segev87:sigmod} propose a structured language for
querying \acro{TSMS}. Their time series structures include the notion
of regularity and temporal representation and their operations are
\acro{SQL}-like.  Dreyer et al.~\cite{dreyer94} suggest the
requirements of a special purpose \acro{TSMS} and base the model on
five basic structural elements: events, time series, groups, metadata
and time series bases. They implement a \acro{TSMS} named
\emph{Calanda} which includes calendar operations, it allows grouping
of time series and it operates with simple queries. They exemplify it
with financial data. In~\cite{schmidt95} \emph{Calanda} is compared
with temporal systems designed for time series.
 
Other authors consider array database systems well suited to
\acro{TSMS}.  \emph{SciDB}~\cite{stonebraker09:scidb} and
\emph{SciQL}~\cite{zhang11} are array database systems intended for
science applications, in which time series play a principal role. They
structure time series into arrays to achieve multidimensional analysis
and they store other data into tables.  \emph{SciDB} is based on
arrays which, according to the authors, allow to represent time
series.  In contrast, \emph{SciQL} defines time series as a mixture of
array, set, and sequence properties and exhibits some time series
managing characteristics that include time series regularities,
interpolation or correlation queries.
% However,
% difference between tables and arrays seems too physical and leads to
% ambiguity when representing time series.  
% Our TSMS model proposes time
% series as firmly based on relational algebra, clarifying this
% ambiguity and describing them coherently in terms of information
% systems theory.


\emph{Bitemporal} \acro{DBMS}, sometimes referred directly as
\emph{temporal data}, is a database field that inherently considers
temporal dimension of data. Bitemporal data manages historical data
and events in databases by associating pairs of \emph{valid} and
\emph{transaction} time intervals to data.  Bitemporal data and time
series data are not exactly the same and so cannot be treated
interchangeably~\cite{schmidt95}, however, there are some similarities
that can be considered. Moreover, \acro{DBMS} research represents
bitemporal data as relations extended with time intervals attributes
and extends relational operations in order to deal with related time
aspects~\cite{jensen99:temporaldata,date02:_tempor_data_relat_model}.
% On the other hand, some bitemporal time concepts might be taken
% into account by \acro{TSMS}, such as the discussions about time
% granularities.



\subsection{Compression approaches}

Oetiker's \emph{RRDtool}~\cite{rrdtool,lisa98:oetiker} is a free
software database management system. It is designed to be used for
monitoring systems. Because of this, it is focused to a particular
kind of data, gauges and counters, and it lacks general time series
operations. \emph{RRDtool} can store multiple time resolution data,
however Plonka et al.~\cite{lisa07:plonka} evaluated \emph{RRDtool}
performance and found limitations when storing a huge number of
different time series. They suggest a caching system on top of
\emph{RRDtool} as a solution.
%
Weigel et al.~\cite{weigel10} advocate a similar approach named
\emph{TSDS} that caches queries by aggregate parameters.  In his
paper, the authors state that other systems only show subsets of data
but it is also necessary to show data in their complete time span.
They develop the software package \emph{TSDS} where time series are
fully stored and then queried by date ranges or by applying different
filters and operations to the time series data.  

Deri et al.~\cite{deri12:tsdb_compressed_database} suggest
\emph{Tsdb}, a lossless compression storage \acro{TSMS} for time
series that share the same time instants of acquisition. Different
time series are stored grouped by the time of acquisition instead of
in a isolated way.  They compare \emph{Tsdb} with \emph{RRDtool} and
with a relational product. As a consequence of \emph{Tsdb} structure,
they achieve a better measure addition time but a worse global
retrieval time as data have to be contiguously regrouped. However,
when the measurements share the same time, a \acro{MTSMS} considers
them as the same time series. Thus, when having much equal acquired
time series, it would be interesting to use the \emph{Tsdb}
implementation architecture of shared time arrays in \acro{MTSMS} to
achieve better performance requirements.

Some lossy compression techniques for time series are devoted to the
optimal approximation representation. They seek to balance between the
least data that can reconstruct the original signal and the least
error. Keogh et al.~\cite{keogh01} cite some possible approximation
representations for time series such as Fourier transforms, wavelets,
symbolic mappings or piecewise linear representation. They remark this
last one as very usual due to its simplicity and develop a system
called \emph{iSAX}~\cite{keogh08:isax,keogh10:isax} in order to
analyse and index massive collections of time series. They describe
that the main problem is in the indexing of time series and they
propose methods for processing efficiently. The first method proposed
is based on a constant piecewise approximation. The time series
representation obtained with \emph{iSAX} allows reducing the stored
space and indexing faster with the same quality as other more complex
representation methods.  These compression techniques are candidates
for being used as attribute aggregate functions in the \acro{MTSMS}
model, as instance it would be interesting to define aggregations in
the frequency domain of time series.


\subsection{Data stream approaches}

\emph{Cougar}~\cite{bonnet01} is a sensor database system that has two
main structures: one for sensor properties that are stored into
relational tables and another for time series coming from sensors that
are stored into data sequences. Time series have specific operations
and can combine relations and sequences. \emph{Cougar} target field is
sensor networks, where data are stored distributed in different
locations. Queries are resolved combining sensor data in a data stream
abstraction that improves processing performance.

Time series are also considered as data streams to aggregate data
statistically. Cormode et al.~\cite{cormode08:pods} develop
aggregation techniques that give more weight to recent data and that
allow to do fast approximate queries with compressed data.

Dou et al.~\cite{dou14:historic_queries_flash_storage} create index
structures as multiresolution aggregates, like average, count, or top,
for historical data managed in flash storage. They consider a specific
storage solution based on a register with pointers similar to the
multiresolution storage in \emph{RRDtool}~\cite{lisa98:oetiker}.



\section{Multiresolution motivation}
\label{sec:features}

An important characteristic of the model formalised in this paper is
\emph{multiresolution}.  Previously to this paper's complete
formalisation for the \acro{MTSMS} model, we analysed the requirements
and we summarised the main target for multiresolution systems
\cite{llusa13:aiked}.

In this section we motivate the advantages of the multiresolution
approach. First, we intuitively introduce the concept of
multiresolution through an example. Then, we discuss the advantages of
this approach.

Figure~\ref{fig:mtsms:sequence} shows an example of the
multiresolution approach. 
%
In the upper part there is a representation of a signal being
monitored. The signal values range from $0$ to $10$ along the
time. There are two specific time instants marked in the figure:
\begin{enumerate}
\item The first is marked with the word \emph{init} and refers to the
  instant in which the database started to receive signal samples.
\item The second is marked with the word \emph{now} and refers to the
  instant in which the process snapshot was made.
\end{enumerate}
Note that time coordinates are assumed to be positive for the times
after \emph{init} and negative otherwise. The time before \emph{now}
corresponds to the past and the time after to the future.
The data before \emph{init} are unknown to the database.

\begin{figure}
  \centering
  %\tikzsetnextfilename{fig_mtsms_sequence}
  %\input{imatges/mtsms_sequence.tex}
  \includegraphics{fig_mtsms_sequence.pdf}
  \caption{Multiresolution snapshot diagram with regular sampling}
  \label{fig:mtsms:sequence}
\end{figure}

At the bottom of Figure~\ref{fig:mtsms:sequence} there is a diagram
that shows how multiresolution works.
%
The first row shows the signal's sample values that correspond to the
above plot. The sampling frequency is of one time unit.
%
The second and the third row show an actual schema of a
multiresolution database. It consists of two summaries for the time
series resolutions. Every summary has a distinct resolution.
%
The first of the rows computes the mean of the sampled values every three units.
The second computes the mean every five units.
%
In this example, aggregation function corresponds to a statistical
mean. The values before \emph{init} are not acquired and they are
marked as unknown (\emph{u}). Future values are also marked as unknown
\emph{u} until time advances. Therefore, the first summary for the
original signal at \emph{now} time corresponds to values
$\{u,u,2,5,8,u\}$.

%%%%%%%%%%%%%%%%%%%%%%%%%

The multiresolution approach enhances \acro{TSMS} features in several
aspects:

\begin{itemize}
\item Voluminous data. Monitoring systems capture a huge amount of
  data from sensors. To be able to process these data, their volume must
  be reduced. The multiresolution approach allows to select and store
  only the most interesting segments of data. These segments are seen
  as different resolutions for the same time series and the user can
  configure how they are extracted and summarised by defining
  different time steps and functions. Multiresolution also facilitates
  the graphing of huge time series by allowing to select the best time
  range and time step that fits into the screen: there is no need to
  render more data if cannot be appreciated in the screen.

\item Data validation. The use of monitoring systems to capture data
  is a current practice. However, the nature of these systems has some
  drawbacks that will have impact on the obtained data. Quevedo et
  al.~\cite{quevedo10} note that the main problems arise when monitors
  cannot capture data, producing errors known as gaps, or monitors
  capture data erroneously.  The multiresolution
  attribute functions are designed to cope well with validation,
  filtering and reconstruction of these unknown data in order to keep
  a consistent history.

\item Data time regularisation. To monitor with a non constant
  sampling rate has a side effect that induces irregularities in data.
  According to Kopetz~\cite{kopetz11:realtime} there are two main
  reasons for sampling rate variation: the sampling jitters in
  periodic sampling or the non periodic event-based sampling.
  Multiresolution regularises the time interval while processing a
  time series. As a consequence, every obtained time series segment
  has a regular time resolution. This feature can also be used to
  query the time series using some other resolution. For instance, a daily
  acquired time series can be queried using a yearly step.

\item Data summaries. The target of a database system is to answer the
  user queries about the stored information. The multiresolution
  approach allows a lossy compression storage solution. This can be
  thought as an online way to compute and store a number of data
  summaries, i.e. data of interest. These stored data summaries
  allow faster queries of voluminous data. However, they should be
  determined a priori, considering the context where the future queries
  will be issued.
\end{itemize}






%%% Local Variables:
%%% TeX-master: "main"
%%% ispell-local-dictionary: "british"
%%% End:

%  LocalWords:  multiresolution TSMS MTSMS timestamp timestamps equi
%  LocalWords:  SQL NoSQL NewSQL et al metadata Segev Shoshani Dreyer
%  LocalWords:  Calanda Quevedo Kopetz outliers
