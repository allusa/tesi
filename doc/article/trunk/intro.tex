\section{Introduction}

Modern society depends on the smooth operation of many complex
engineering systems which provides products and services. Examples
include electric power systems, water distributions networks,
transportation systems, manufacturing processes, intelligent
buildings, communication systems, etc. The emergence of networked
embedded systems and sensor/actuator networks has made possible the
collection of large amounts of data for monitoring and control of such
complex systems. In most application, these data need to be processed
and synthesised efficiently to provide relevant information to
engineers, researchers, accident investigators, operators, and many
other users.  

Nevertheless, before using the collected signals, it is of primary
importance to promptly detecting eventual sensor failures or
malfunctions and possibly reconstructing the incorrect signals in
order to avoid processing misleading information which may lead to
unsafe and/or inefficient actions.  In all these instances a measure
is associated with a time stamp, which implies that the correctness of
those data depends not only on the measured value but also on the time
as it is collected. When observations are collected at specific time
interval, large data sets in the form of time series are
generated~\cite{basu07:_autom}.  

Time series are defined as a collection of observations made
chronologically \cite{fu11}, in \cite{last:hetland} they are also
called time sequences.  Time series are usually stored in a
database. Usually the managing software to store this data are
relational database management systems (RDBMS). However, using a RDBMS
as a time series backend suffers some drawbacks
\cite{dreyer94,schmidt95,stonebraker09:scidb,zhang11}. Time series
come from a continuous nature in which they are recorded at regular
intervals, such as hourly or daily, or at irregular intervals, such as
recording when a pump is open or closed.

One problem when dealing with time series data results from the fact
that these data are often voluminous \cite{fu11}. As a result, storing
and accessing them can be complicated. Moreover, it is specially
critical when developing small embedded systems, whose resources
(capacity, energy, processing, and communications) suffer a genuine
restriction \cite{yaogehrke02}.  Another problem is that the procedure
of processing and synthesising information becomes complicated if data
is not equi-time spaced.



%TSMS

This paper focuses on Data Base Management Systems (DBMS) that store
and treat data as time series. These are usually known as Time Series
Data Base Management Systems (TSMS) \cite{dreyer94}.  A TSMS is a
special purpose DBMS aimed at storing and managing time series

The main objective of TSMS is to put together two areas of study: time
series analysis and DBMS.  Time series analysis theory studies
formally a great amount of algorithms and methodologies that apply to
time series, focusing on efficiency improving. DBMS theory studies
systems that store and operate with data; currently the relation model
\cite{date:introduction} is the referent.

%TSMS features

In time series analysis there are some common operations that can be
generalised when treating time series.

The main attribute of time series is the time, therefore dealing with
time is a common operation, such as querying time intervals, finding
time correlations, or calculating distances between two time
series. TSMS must respect the temporal coherence of the time series.
In the context of statistics, aggregation of time series is also
common operation. Aggregation consists in summarising a time series
subset with an statistic such as the mean, the maximum, or the mode.

A particular feature of time series is representation. A time series
is discrete in the set sense, that is a set of value and time
pairs. Representation is the function model approximating the time
series to its continuous nature. TSMS operate on time series
respecting the representation coherence. Furthermore, the values of a
time series can be of any type; for simplicity examples are presented
generally with integers or real numbers but can also be strings or
structures such as arrays.
% , preferably using piecewise operations in the set domain rather
% than solving numerical methods for the continuous domain.


%Related work
There are some prior works concerning TSMS. RRDtool from Oetiker
\cite{rrdtool} is a free software database management system. It is
designed to be used in monitoring systems. Because of this, it is
focused to a particular kind of data, gauges and counters, and it
lacks general time series operations. RRDtool can store multiple time
resolution data. The work in this paper is partially inspired in
RRDtool.

Cougar \cite{bonnet01} is a sensor database system. It has two
structures: one for sensor properties stored into relations and
another for time series stored into data sequences from sensors. Time
series have specific operations and can combine relations and
sequences. Cougar target field is sensor networks, where sensor data
is stored distributed in sensors. Queries are resolved combining
sensor data in a data stream orientation, which improves processing
performance. However, data streams imposes restriction on operators so
this TSMS can not be generalised to other time series types. Moreover,
sequences and relations can collide in representing ambiguously time
series.


SciDB \cite{stonebraker09:scidb} and SciQL \cite{zhang11} are array
database systems. These systems are intended for science applications,
in which time series play a principal role. They structure time series
into arrays in order to achieve multidimensional analysis and allow
tables to store other data.  Although SciDB is based on arrays, in
which it includes time series, it does not consider time series
special needs, that is not considering how continuously voluminous
data or temporal coherence are achieved.  In contrast, SciQL shows how
some time series properties are achieved by the DBMS such as time
series regularities, interpolation or correlation queries.  However,
difference between tables and arrays seems too physical approached an
consequently can collide in representing ambiguously time series.


Bitemporal data and time series data are not exactly the same and so
can not be treated interchangeably \cite{schmidt95}. However, there
are some similarities between time series and bitemporal data that can
be considered. First, extending a relational database model to manage
bitemporal data shows the way to extend relational DBMS with new types
and how to model them. Second, bitemporal data modelling settles some
time-related concepts that can be extended to time series.

The recent bitemporal data research in relational DBMS model terms
\cite{date02:_tempor_data_relat_model} marks a promising
foundation. It models bitemporal data as relations extended with time
intervals attributes and extends relational operations in order to
deal with related time aspects.




%MTSMS

In this paper, we introduce a new data model for a TSMS: a TSMS with
multiresolution capabilities. This model allows to store time series
using different time resolutions and organised in a relation way. The
model is specifically designed to cope well with bounded storage
computers like those found in sensor systems.

MTSMS improve TSMS features in various aspects:
\begin{itemize}

\item Voluminous data. Monitoring systems capture a huge amount of
  data from sensors. In order to be able to process this information,
  data volume must be reduced. With the multiresolution approach only
  the most interesting segments of data are stored. This segments are
  seen as different resolutions for the same time series and the user
  configures how they are extracted and summarised by defining
  different interpolation steps and functions. Multiresolution can
  also be useful at visualisation time as the user is able to select
  the best time range and time step that fits into the screen; there
  is no need to process with more quantity of data than the one that
  can be shown.

\item Data validation. Monitoring systems capture data but can occur
  some drawbacks that will affect later the process of time series
  analysis. Main problems are found when monitors can not capture
  data, known as gaps, or capture data erroneously, such as outlayers.
  The multiresolution attribute functions cope well with validating,
  filtering and calculating with this unknown data in order to keep a
  consistent historic.

\item Data time regularising. Another monitoring side effect happens when
  the sampling rate is not constant, that is when the resulting data
  is not equi-time spaced. This no regularities can come from sampling
  jitters in periodic sampling or from no periodic event-based
  sampling. The multiresolution consolidation regularises the time
  interval when processes a time series, therefore each resulting time
  series segment has a regular time resolution. This regularising
  approach could also be used when the user wants to consult another
  resolution for a time series, such as changing periodic data from a
  month to a year step.

\item Information summaries. Time series analysis typically focuses on
  reconstructing the original signal. However, the user objective in a
  database system is to consult some information. The multiresolution
  approach is a lossy compression storage solution for data. Therefore
  it can be regarded as not only approximating to the
  original time series function but also extracting the interesting
  information. The selected information must be determined a priori
  assuming the context where the future queries will be done.

\end{itemize}





** Paper structure **\todo{}








%%% Local Variables:
%%% TeX-master: "main"
%%% ispell-local-dictionary: "british"
%%% End:

% LocalWords:  multiresolution
